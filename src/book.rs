//! High-level EPUB API for common workflows.
//!
//! This module provides a convenience wrapper around the lower-level parsers.
//! It is intended for the common "open EPUB -> inspect metadata -> read chapters"
//! flow.

extern crate alloc;

use alloc::format;
use alloc::string::{String, ToString};
use alloc::vec::Vec;
use core::str;
use quick_xml::events::Event;
use quick_xml::reader::Reader;
use std::fs::File;
use std::io::{Read, Seek, Write};
use std::path::Path;

use crate::error::{EpubError, ZipError};
use crate::metadata::{extract_metadata, EpubMetadata};
use crate::navigation::{parse_nav_xhtml, parse_ncx, NavPoint, Navigation};
use crate::render_prep::{
    parse_font_faces_from_css, parse_stylesheet_links, ChapterStylesheets, EmbeddedFontFace,
    FontLimits, RenderPrep, RenderPrepOptions, StyleLimits, StyledChapter, StylesheetSource,
};
use crate::spine::Spine;
use crate::tokenizer::{tokenize_html, Token};
use crate::zip::{StreamingZip, ZipLimits};

/// Validation strictness for high-level open/parse flows.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Default)]
#[non_exhaustive]
pub enum ValidationMode {
    /// Best-effort behavior for partial/quirky EPUBs.
    #[default]
    Lenient,
    /// Fail early for structural inconsistencies.
    Strict,
}

/// High-level configuration for opening EPUB books.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub struct EpubBookOptions {
    /// Optional ZIP safety limits used while reading archive entries.
    ///
    /// When `None`, no explicit file-size caps are enforced by this crate.
    pub zip_limits: Option<ZipLimits>,
    /// Validation strictness for high-level parse/open behavior.
    pub validation_mode: ValidationMode,
}

impl Default for EpubBookOptions {
    fn default() -> Self {
        Self {
            zip_limits: None,
            validation_mode: ValidationMode::Lenient,
        }
    }
}

/// Builder for ergonomic high-level EPUB opening/parsing.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Default)]
pub struct EpubBookBuilder {
    options: EpubBookOptions,
}

impl EpubBookBuilder {
    /// Create a new builder with no explicit limits.
    pub fn new() -> Self {
        Self::default()
    }

    /// Set explicit ZIP limits.
    pub fn with_zip_limits(mut self, limits: ZipLimits) -> Self {
        self.options.zip_limits = Some(limits);
        self
    }

    /// Enable strict validation mode.
    pub fn strict(mut self) -> Self {
        self.options.validation_mode = ValidationMode::Strict;
        self
    }

    /// Set explicit validation mode.
    pub fn validation_mode(mut self, mode: ValidationMode) -> Self {
        self.options.validation_mode = mode;
        self
    }

    /// Open an EPUB from a file path.
    pub fn open<P: AsRef<Path>>(self, path: P) -> Result<EpubBook<File>, EpubError> {
        EpubBook::open_with_options(path, self.options)
    }

    /// Open an EPUB from an arbitrary reader.
    pub fn from_reader<R: Read + Seek>(self, reader: R) -> Result<EpubBook<R>, EpubError> {
        EpubBook::from_reader_with_options(reader, self.options)
    }

    /// Parse summary metadata from a file path.
    pub fn parse_file<P: AsRef<Path>>(self, path: P) -> Result<EpubSummary, EpubError> {
        parse_epub_file_with_options(path, self.options)
    }

    /// Parse summary metadata from an arbitrary reader.
    pub fn parse_reader<R: Read + Seek>(self, reader: R) -> Result<EpubSummary, EpubError> {
        parse_epub_reader_with_options(reader, self.options)
    }
}

/// Parsed top-level EPUB data for lightweight usage.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct EpubSummary {
    metadata: EpubMetadata,
    spine: Spine,
    navigation: Option<Navigation>,
}

impl EpubSummary {
    /// EPUB package metadata.
    pub fn metadata(&self) -> &EpubMetadata {
        &self.metadata
    }

    /// Reading order from `<spine>`.
    pub fn spine(&self) -> &Spine {
        &self.spine
    }

    /// Parsed navigation document, when one is available.
    pub fn navigation(&self) -> Option<&Navigation> {
        self.navigation.as_ref()
    }
}

/// Parse an EPUB from any `Read + Seek` source.
pub fn parse_epub_reader<R: Read + Seek>(reader: R) -> Result<EpubSummary, EpubError> {
    parse_epub_reader_with_options(reader, EpubBookOptions::default())
}

/// Parse an EPUB from any `Read + Seek` source with explicit options.
pub fn parse_epub_reader_with_options<R: Read + Seek>(
    reader: R,
    options: EpubBookOptions,
) -> Result<EpubSummary, EpubError> {
    let mut zip =
        StreamingZip::new_with_limits(reader, options.zip_limits).map_err(EpubError::Zip)?;
    load_summary_from_zip(&mut zip, options)
}

/// Parse an EPUB from a file path.
pub fn parse_epub_file<P: AsRef<Path>>(path: P) -> Result<EpubSummary, EpubError> {
    parse_epub_file_with_options(path, EpubBookOptions::default())
}

/// Parse an EPUB from a file path with explicit options.
pub fn parse_epub_file_with_options<P: AsRef<Path>>(
    path: P,
    options: EpubBookOptions,
) -> Result<EpubSummary, EpubError> {
    let file = File::open(path).map_err(|e| EpubError::Io(e.to_string()))?;
    parse_epub_reader_with_options(file, options)
}

/// High-level EPUB handle backed by an open ZIP reader.
pub struct EpubBook<R: Read + Seek> {
    zip: StreamingZip<R>,
    opf_path: String,
    metadata: EpubMetadata,
    spine: Spine,
    navigation: Option<Navigation>,
}

/// Lightweight chapter descriptor in spine order.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct ChapterRef {
    /// Spine position index.
    pub index: usize,
    /// Spine `idref`.
    pub idref: String,
    /// Manifest href relative to OPF.
    pub href: String,
    /// Manifest media type.
    pub media_type: String,
}

/// Stable reading position with anchor + fallback offset information.
#[derive(Clone, Debug, Default, PartialEq, Eq)]
pub struct ReadingPosition {
    /// 0-based chapter index in spine order.
    pub chapter_index: usize,
    /// Optional chapter href hint for robust restore across index shifts.
    pub chapter_href: Option<String>,
    /// Optional anchor payload (fragment id or CFI-like token).
    pub anchor: Option<String>,
    /// Fallback character offset in the chapter when anchor cannot be resolved.
    pub fallback_offset: usize,
}

/// Semantic navigation primitive for seeking/resolve operations.
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum Locator {
    /// Resolve by chapter index.
    Chapter(usize),
    /// Resolve by chapter href (optionally with `#fragment`).
    Href(String),
    /// Resolve a fragment in the current chapter context.
    Fragment(String),
    /// Resolve by TOC id (mapped from nav href fragment or label).
    TocId(String),
    /// Resolve from a persisted reading position.
    Position(ReadingPosition),
}

/// Fully resolved location information returned from locator APIs.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct ResolvedLocation {
    /// Resolved chapter descriptor.
    pub chapter: ChapterRef,
    /// Optional resolved fragment (without leading '#').
    pub fragment: Option<String>,
    /// Canonical position payload for persistence.
    pub position: ReadingPosition,
}

/// Lightweight mutable reading session detached from ZIP/file state.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct ReadingSession {
    chapters: Vec<ChapterRef>,
    navigation: Option<Navigation>,
    current: ReadingPosition,
}

impl ReadingSession {
    /// Create a reading session from chapter descriptors and optional navigation.
    pub fn new(chapters: Vec<ChapterRef>, navigation: Option<Navigation>) -> Self {
        let first_href = chapters.first().map(|c| c.href.clone());
        Self {
            chapters,
            navigation,
            current: ReadingPosition {
                chapter_index: 0,
                chapter_href: first_href,
                anchor: None,
                fallback_offset: 0,
            },
        }
    }

    /// Return current stable reading position.
    pub fn current_position(&self) -> ReadingPosition {
        self.current.clone()
    }

    /// Seek to an explicit reading position.
    pub fn seek_position(&mut self, pos: &ReadingPosition) -> Result<(), EpubError> {
        if pos.chapter_index >= self.chapters.len() {
            return Err(EpubError::ChapterOutOfBounds {
                index: pos.chapter_index,
                chapter_count: self.chapters.len(),
            });
        }
        self.current = pos.clone();
        if self.current.chapter_href.is_none() {
            self.current.chapter_href = Some(self.chapters[pos.chapter_index].href.clone());
        }
        Ok(())
    }

    /// Chapter-local progress ratio in `[0.0, 1.0]`.
    pub fn chapter_progress(&self) -> f32 {
        if self.chapters.is_empty() {
            return 0.0;
        }
        if self.current.fallback_offset == 0 {
            0.0
        } else {
            1.0
        }
    }

    /// Whole-book progress ratio in `[0.0, 1.0]`.
    pub fn book_progress(&self) -> f32 {
        if self.chapters.is_empty() {
            return 0.0;
        }
        let chapter_ratio = self.chapter_progress();
        ((self.current.chapter_index as f32) + chapter_ratio) / (self.chapters.len() as f32)
    }

    /// Resolve a semantic locator to a concrete chapter/fragment location.
    pub fn resolve_locator(&mut self, loc: Locator) -> Result<ResolvedLocation, EpubError> {
        match loc {
            Locator::Chapter(index) => {
                let chapter =
                    self.chapters
                        .get(index)
                        .cloned()
                        .ok_or(EpubError::ChapterOutOfBounds {
                            index,
                            chapter_count: self.chapters.len(),
                        })?;
                self.current.chapter_index = index;
                self.current.chapter_href = Some(chapter.href.clone());
                self.current.anchor = None;
                Ok(ResolvedLocation {
                    chapter,
                    fragment: None,
                    position: self.current.clone(),
                })
            }
            Locator::Href(href) => {
                let (base, fragment) = split_href_fragment(&href);
                let (index, chapter) = self
                    .chapters
                    .iter()
                    .enumerate()
                    .find(|(_, chapter)| chapter.href == base)
                    .map(|(idx, chapter)| (idx, chapter.clone()))
                    .ok_or_else(|| {
                        EpubError::InvalidEpub(format!("unknown chapter href: {}", href))
                    })?;
                self.current.chapter_index = index;
                self.current.chapter_href = Some(chapter.href.clone());
                self.current.anchor = fragment.clone();
                Ok(ResolvedLocation {
                    chapter,
                    fragment,
                    position: self.current.clone(),
                })
            }
            Locator::Fragment(fragment) => {
                let idx = self
                    .current
                    .chapter_index
                    .min(self.chapters.len().saturating_sub(1));
                let chapter =
                    self.chapters
                        .get(idx)
                        .cloned()
                        .ok_or(EpubError::ChapterOutOfBounds {
                            index: idx,
                            chapter_count: self.chapters.len(),
                        })?;
                self.current.chapter_index = idx;
                self.current.chapter_href = Some(chapter.href.clone());
                self.current.anchor = Some(fragment.clone());
                Ok(ResolvedLocation {
                    chapter,
                    fragment: Some(fragment),
                    position: self.current.clone(),
                })
            }
            Locator::TocId(id) => {
                let nav = self.navigation.as_ref().ok_or_else(|| {
                    EpubError::Navigation("no navigation document available".to_string())
                })?;
                let href = find_toc_href(nav, &id).ok_or_else(|| {
                    EpubError::Navigation(format!("toc id/label not found: {}", id))
                })?;
                self.resolve_locator(Locator::Href(href))
            }
            Locator::Position(pos) => {
                self.seek_position(&pos)?;
                self.resolve_locator(Locator::Chapter(pos.chapter_index))
            }
        }
    }
}

fn split_href_fragment(href: &str) -> (String, Option<String>) {
    if let Some((base, fragment)) = href.split_once('#') {
        return (base.to_string(), Some(fragment.to_string()));
    }
    (href.to_string(), None)
}

fn find_toc_href(nav: &Navigation, id: &str) -> Option<String> {
    fn visit(points: &[NavPoint], id: &str) -> Option<String> {
        for point in points {
            let (_, fragment) = split_href_fragment(&point.href);
            if point.label == id || fragment.as_deref() == Some(id) {
                return Some(point.href.clone());
            }
            if let Some(hit) = visit(&point.children, id) {
                return Some(hit);
            }
        }
        None
    }
    visit(&nav.toc, id)
}

impl EpubBook<File> {
    /// Open an EPUB from disk and parse core structures.
    pub fn open<P: AsRef<Path>>(path: P) -> Result<Self, EpubError> {
        Self::open_with_options(path, EpubBookOptions::default())
    }

    /// Open an EPUB from disk with explicit options.
    pub fn open_with_options<P: AsRef<Path>>(
        path: P,
        options: EpubBookOptions,
    ) -> Result<Self, EpubError> {
        let file = File::open(path).map_err(|e| EpubError::Io(e.to_string()))?;
        Self::from_reader_with_options(file, options)
    }
}

impl<R: Read + Seek> EpubBook<R> {
    /// Open an EPUB from any `Read + Seek` source and parse core structures.
    pub fn from_reader(reader: R) -> Result<Self, EpubError> {
        Self::from_reader_with_options(reader, EpubBookOptions::default())
    }

    /// Open an EPUB from any `Read + Seek` source and parse core structures.
    pub fn from_reader_with_options(
        reader: R,
        options: EpubBookOptions,
    ) -> Result<Self, EpubError> {
        let mut zip =
            StreamingZip::new_with_limits(reader, options.zip_limits).map_err(EpubError::Zip)?;
        zip.validate_mimetype().map_err(EpubError::Zip)?;

        let container = read_entry(&mut zip, "META-INF/container.xml")?;
        let opf_path = crate::metadata::parse_container_xml(&container)?;
        let opf = read_entry(&mut zip, &opf_path)?;
        let metadata = extract_metadata(&container, &opf)?;
        let spine = crate::spine::parse_spine(&opf)?;
        validate_open_invariants(&metadata, &spine, options.validation_mode)?;
        let navigation = parse_navigation(
            &mut zip,
            &metadata,
            &spine,
            &opf_path,
            options.validation_mode,
        )?;

        Ok(Self {
            zip,
            opf_path,
            metadata,
            spine,
            navigation,
        })
    }

    /// EPUB package metadata.
    pub fn metadata(&self) -> &EpubMetadata {
        &self.metadata
    }

    /// Convenience: metadata title.
    pub fn title(&self) -> &str {
        self.metadata.title.as_str()
    }

    /// Convenience: metadata author.
    pub fn author(&self) -> &str {
        self.metadata.author.as_str()
    }

    /// Convenience: metadata language.
    pub fn language(&self) -> &str {
        self.metadata.language.as_str()
    }

    /// Reading order from `<spine>`.
    pub fn spine(&self) -> &Spine {
        &self.spine
    }

    /// Parsed navigation document, when one is available.
    pub fn navigation(&self) -> Option<&Navigation> {
        self.navigation.as_ref()
    }

    /// Convenience: top-level TOC entries from parsed navigation.
    pub fn toc(&self) -> Option<&[NavPoint]> {
        self.navigation.as_ref().map(|n| n.toc.as_slice())
    }

    /// Number of entries in the spine reading order.
    pub fn chapter_count(&self) -> usize {
        self.spine.len()
    }

    /// Create a detached reading session for locator/progress operations.
    pub fn reading_session(&self) -> ReadingSession {
        ReadingSession::new(self.chapters().collect(), self.navigation.clone())
    }

    /// Enumerate chapters in spine order.
    pub fn chapters(&self) -> impl Iterator<Item = ChapterRef> + '_ {
        self.spine
            .items()
            .iter()
            .enumerate()
            .filter_map(|(index, spine_item)| {
                self.metadata
                    .get_item(&spine_item.idref)
                    .map(|manifest_item| ChapterRef {
                        index,
                        idref: spine_item.idref.clone(),
                        href: manifest_item.href.clone(),
                        media_type: manifest_item.media_type.clone(),
                    })
            })
    }

    /// Get a chapter descriptor by spine index.
    pub fn chapter(&self, index: usize) -> Result<ChapterRef, EpubError> {
        let spine_item = self
            .spine
            .get_item(index)
            .ok_or(EpubError::ChapterOutOfBounds {
                index,
                chapter_count: self.spine.len(),
            })?;

        let manifest_item = self.metadata.get_item(&spine_item.idref).ok_or_else(|| {
            EpubError::ManifestItemMissing {
                idref: spine_item.idref.clone(),
            }
        })?;

        Ok(ChapterRef {
            index,
            idref: spine_item.idref.clone(),
            href: manifest_item.href.clone(),
            media_type: manifest_item.media_type.clone(),
        })
    }

    /// Get a chapter descriptor by spine `idref`.
    pub fn chapter_by_id(&self, idref: &str) -> Result<ChapterRef, EpubError> {
        let index = self
            .spine
            .items()
            .iter()
            .position(|item| item.idref == idref)
            .ok_or_else(|| EpubError::ManifestItemMissing {
                idref: idref.to_string(),
            })?;
        self.chapter(index)
    }

    /// Read a resource by OPF-relative href.
    ///
    /// Fragment suffixes (e.g. `chapter.xhtml#p3`) are ignored.
    pub fn read_resource(&mut self, href: &str) -> Result<Vec<u8>, EpubError> {
        let mut out = Vec::new();
        self.read_resource_into(href, &mut out)?;
        Ok(out)
    }

    /// Stream a resource by OPF-relative href into a writer.
    ///
    /// Fragment suffixes (e.g. `chapter.xhtml#p3`) are ignored.
    pub fn read_resource_into<W: Write>(
        &mut self,
        href: &str,
        writer: &mut W,
    ) -> Result<usize, EpubError> {
        let zip_path = resolve_opf_relative_path(&self.opf_path, href);
        read_entry_into(&mut self.zip, &zip_path, writer)
    }

    /// Read spine item content bytes by index.
    pub fn read_spine_item_bytes(&mut self, index: usize) -> Result<Vec<u8>, EpubError> {
        let href = self.chapter(index)?.href;

        self.read_resource(&href)
    }

    /// Read a spine chapter as UTF-8 HTML/XHTML text by index.
    pub fn chapter_html(&mut self, index: usize) -> Result<String, EpubError> {
        let chapter = self.chapter(index)?;
        let bytes = self.read_resource(&chapter.href)?;
        String::from_utf8(bytes).map_err(|_| EpubError::ChapterNotUtf8 { href: chapter.href })
    }

    /// Resolve chapter stylesheet sources in cascade order.
    pub fn chapter_stylesheets(&mut self, index: usize) -> Result<ChapterStylesheets, EpubError> {
        self.chapter_stylesheets_with_options(index, StyleLimits::default())
    }

    /// Resolve chapter stylesheet sources in cascade order with explicit limits.
    pub fn chapter_stylesheets_with_options(
        &mut self,
        index: usize,
        limits: StyleLimits,
    ) -> Result<ChapterStylesheets, EpubError> {
        let chapter = self.chapter(index)?;
        let html = self.chapter_html(index)?;
        let links = parse_stylesheet_links(&chapter.href, &html);
        let mut sources = Vec::new();

        for href in links {
            let bytes = self.read_resource(&href)?;
            if bytes.len() > limits.max_css_bytes {
                return Err(EpubError::Parse(format!(
                    "Stylesheet exceeds max_css_bytes ({} > {}) at '{}'",
                    bytes.len(),
                    limits.max_css_bytes,
                    href
                )));
            }
            let css = String::from_utf8(bytes)
                .map_err(|_| EpubError::Parse(format!("Stylesheet is not UTF-8: {}", href)))?;
            sources.push(StylesheetSource { href, css });
        }

        Ok(ChapterStylesheets { sources })
    }

    /// Enumerate embedded font-face metadata from EPUB CSS resources.
    pub fn embedded_fonts(&mut self) -> Result<Vec<EmbeddedFontFace>, EpubError> {
        self.embedded_fonts_with_options(FontLimits::default())
    }

    /// Enumerate embedded font-face metadata with explicit limits.
    pub fn embedded_fonts_with_options(
        &mut self,
        limits: FontLimits,
    ) -> Result<Vec<EmbeddedFontFace>, EpubError> {
        let css_hrefs: Vec<String> = self
            .metadata
            .manifest
            .iter()
            .filter(|item| item.media_type == "text/css")
            .map(|item| item.href.clone())
            .collect();

        let mut out = Vec::new();
        for href in css_hrefs {
            let bytes = self.read_resource(&href)?;
            let css = String::from_utf8(bytes)
                .map_err(|_| EpubError::Parse(format!("Stylesheet is not UTF-8: {}", href)))?;
            for face in parse_font_faces_from_css(&href, &css) {
                out.push(face);
                if out.len() > limits.max_faces {
                    return Err(EpubError::Parse(format!(
                        "Embedded font face count exceeds max_faces ({})",
                        limits.max_faces
                    )));
                }
            }
        }
        Ok(out)
    }

    /// Style chapter content into an event/run stream with default options.
    pub fn chapter_styled_runs(&mut self, index: usize) -> Result<StyledChapter, EpubError> {
        self.chapter_styled_runs_with_options(index, RenderPrepOptions::default())
    }

    /// Style chapter content into an event/run stream with explicit options.
    pub fn chapter_styled_runs_with_options(
        &mut self,
        index: usize,
        options: RenderPrepOptions,
    ) -> Result<StyledChapter, EpubError> {
        let mut prep = RenderPrep::new(options).with_serif_default();
        let prepared = prep
            .prepare_chapter(self, index)
            .map_err(|e| EpubError::Parse(e.to_string()))?;
        let mut items = Vec::new();
        for item in prepared.iter() {
            items.push(item.clone());
        }
        Ok(StyledChapter::from_items(items))
    }

    /// Read a chapter and return plain text extracted from token stream.
    ///
    /// For lower memory usage, prefer `chapter_text_into`/`chapter_text_with_limit`.
    pub fn chapter_text(&mut self, index: usize) -> Result<String, EpubError> {
        let mut out = String::new();
        self.chapter_text_into(index, &mut out)?;
        Ok(out)
    }

    /// Extract plain text for a chapter into a caller-provided string buffer.
    ///
    /// This avoids allocating an intermediate `Vec<Token>` and is intended as
    /// the default API for constrained environments.
    pub fn chapter_text_into(&mut self, index: usize, out: &mut String) -> Result<(), EpubError> {
        self.chapter_text_into_with_limit(index, usize::MAX, out)
    }

    /// Extract plain text for a chapter and cap output to `max_bytes`.
    ///
    /// Output is truncated on a UTF-8 boundary when the limit is reached.
    pub fn chapter_text_with_limit(
        &mut self,
        index: usize,
        max_bytes: usize,
    ) -> Result<String, EpubError> {
        let mut out = String::new();
        self.chapter_text_into_with_limit(index, max_bytes, &mut out)?;
        Ok(out)
    }

    /// Extract plain text into caller-provided storage, with a hard byte cap.
    ///
    /// Existing content of `out` is cleared before writing.
    pub fn chapter_text_into_with_limit(
        &mut self,
        index: usize,
        max_bytes: usize,
        out: &mut String,
    ) -> Result<(), EpubError> {
        out.clear();
        if max_bytes == 0 {
            return Ok(());
        }

        let chapter = self.chapter(index)?;
        let bytes = self.read_resource(&chapter.href)?;
        extract_plain_text_limited(&bytes, max_bytes, out)
    }

    /// Tokenize spine item content by index.
    ///
    /// This API allocates a full token vector. Prefer `chapter_text_into` for
    /// low-memory extraction paths.
    pub fn tokenize_spine_item(&mut self, index: usize) -> Result<Vec<Token>, EpubError> {
        let chapter = self.chapter(index)?;
        let bytes = self.read_resource(&chapter.href)?;
        let html =
            str::from_utf8(&bytes).map_err(|_| EpubError::ChapterNotUtf8 { href: chapter.href })?;
        tokenize_html(html).map_err(EpubError::from)
    }

    /// Backward-compatible alias for `read_spine_item_bytes`.
    pub fn read_spine_chapter(&mut self, index: usize) -> Result<Vec<u8>, EpubError> {
        self.read_spine_item_bytes(index)
    }

    /// Backward-compatible alias for `tokenize_spine_item`.
    pub fn tokenize_spine_chapter(&mut self, index: usize) -> Result<Vec<Token>, EpubError> {
        self.tokenize_spine_item(index)
    }
}

impl EpubBook<File> {
    /// Create a high-level builder for opening/parsing EPUBs.
    pub fn builder() -> EpubBookBuilder {
        EpubBookBuilder::new()
    }
}

fn load_summary_from_zip<R: Read + Seek>(
    zip: &mut StreamingZip<R>,
    options: EpubBookOptions,
) -> Result<EpubSummary, EpubError> {
    zip.validate_mimetype().map_err(EpubError::Zip)?;
    let container = read_entry(zip, "META-INF/container.xml")?;
    let opf_path = crate::metadata::parse_container_xml(&container)?;
    let opf = read_entry(zip, &opf_path)?;
    let metadata = extract_metadata(&container, &opf)?;
    let spine = crate::spine::parse_spine(&opf)?;
    validate_open_invariants(&metadata, &spine, options.validation_mode)?;
    let navigation = parse_navigation(zip, &metadata, &spine, &opf_path, options.validation_mode)?;

    Ok(EpubSummary {
        metadata,
        spine,
        navigation,
    })
}

fn parse_navigation<R: Read + Seek>(
    zip: &mut StreamingZip<R>,
    metadata: &EpubMetadata,
    spine: &Spine,
    opf_path: &str,
    validation_mode: ValidationMode,
) -> Result<Option<Navigation>, EpubError> {
    let nav_item = spine
        .toc_id()
        .and_then(|toc_id| metadata.get_item(toc_id))
        .or_else(|| {
            metadata.manifest.iter().find(|item| {
                item.properties
                    .as_deref()
                    .is_some_and(|p| p.split_whitespace().any(|prop| prop == "nav"))
            })
        })
        .or_else(|| {
            metadata.manifest.iter().find(|item| {
                item.media_type == "application/x-dtbncx+xml"
                    || item.href.to_ascii_lowercase().ends_with(".ncx")
            })
        });

    let Some(nav_item) = nav_item else {
        return Ok(None);
    };

    let nav_path = resolve_opf_relative_path(opf_path, &nav_item.href);
    let nav_bytes = match read_entry(zip, &nav_path) {
        Ok(bytes) => bytes,
        Err(err) => {
            if matches!(validation_mode, ValidationMode::Strict) {
                return Err(err);
            }
            log::warn!("Failed to read navigation document '{}': {}", nav_path, err);
            return Ok(None);
        }
    };

    let parsed = if nav_item.media_type == "application/x-dtbncx+xml"
        || nav_item.href.to_ascii_lowercase().ends_with(".ncx")
    {
        parse_ncx(&nav_bytes)
    } else {
        parse_nav_xhtml(&nav_bytes)
    };

    match parsed {
        Ok(nav) => Ok(Some(nav)),
        Err(err) => {
            if matches!(validation_mode, ValidationMode::Strict) {
                Err(EpubError::Navigation(err.to_string()))
            } else {
                log::warn!(
                    "Failed to parse navigation document '{}': {}",
                    nav_path,
                    err
                );
                Ok(None)
            }
        }
    }
}

fn validate_open_invariants(
    metadata: &EpubMetadata,
    spine: &Spine,
    validation_mode: ValidationMode,
) -> Result<(), EpubError> {
    if matches!(validation_mode, ValidationMode::Lenient) {
        return Ok(());
    }

    for item in spine.items() {
        if metadata.get_item(&item.idref).is_none() {
            return Err(EpubError::ManifestItemMissing {
                idref: item.idref.clone(),
            });
        }
    }

    Ok(())
}

fn read_entry<R: Read + Seek>(zip: &mut StreamingZip<R>, path: &str) -> Result<Vec<u8>, EpubError> {
    let mut buf = Vec::new();
    read_entry_into(zip, path, &mut buf)?;
    Ok(buf)
}

fn read_entry_into<R: Read + Seek, W: Write>(
    zip: &mut StreamingZip<R>,
    path: &str,
    writer: &mut W,
) -> Result<usize, EpubError> {
    let entry = zip
        .get_entry(path)
        .cloned()
        .ok_or(EpubError::Zip(ZipError::FileNotFound))?;
    zip.read_file_to_writer(&entry, writer)
        .map_err(EpubError::Zip)
}

fn resolve_opf_relative_path(opf_path: &str, href: &str) -> String {
    let href = href.split('#').next().unwrap_or(href);
    if href.is_empty() {
        return normalize_path(opf_path);
    }
    if href.starts_with('/') {
        return normalize_path(href.trim_start_matches('/'));
    }
    if href.contains("://") {
        return href.to_string();
    }

    let base_dir = opf_path.rsplit_once('/').map(|(dir, _)| dir).unwrap_or("");
    if base_dir.is_empty() {
        normalize_path(href)
    } else {
        normalize_path(&format!("{}/{}", base_dir, href))
    }
}

fn normalize_path(path: &str) -> String {
    let mut parts: Vec<&str> = Vec::new();
    for part in path.split('/') {
        match part {
            "" | "." => {}
            ".." => {
                parts.pop();
            }
            _ => parts.push(part),
        }
    }
    parts.join("/")
}

fn should_skip_text_tag(name: &str) -> bool {
    matches!(
        name,
        "script" | "style" | "head" | "nav" | "header" | "footer" | "aside" | "noscript"
    )
}

fn normalize_plain_text_whitespace(text: &str) -> String {
    let mut result = String::with_capacity(text.len());
    let mut prev_was_space = true;
    for ch in text.chars() {
        if ch.is_whitespace() {
            if !prev_was_space {
                result.push(' ');
                prev_was_space = true;
            }
        } else {
            result.push(ch);
            prev_was_space = false;
        }
    }
    if result.ends_with(' ') {
        result.pop();
    }
    result
}

fn push_limited(out: &mut String, value: &str, max_bytes: usize) -> bool {
    if out.len() >= max_bytes || value.is_empty() {
        return out.len() >= max_bytes;
    }
    let remaining = max_bytes - out.len();
    if value.len() <= remaining {
        out.push_str(value);
        return false;
    }
    let mut end = remaining;
    while !value.is_char_boundary(end) {
        end -= 1;
    }
    if end > 0 {
        out.push_str(&value[..end]);
    }
    true
}

fn push_newline_limited(out: &mut String, max_bytes: usize) -> bool {
    if out.is_empty() || out.ends_with('\n') {
        return false;
    }
    push_limited(out, "\n", max_bytes)
}

fn push_text_limited(out: &mut String, text: &str, max_bytes: usize) -> bool {
    if text.is_empty() {
        return false;
    }
    if !out.is_empty() && !out.ends_with('\n') && push_limited(out, " ", max_bytes) {
        return true;
    }
    push_limited(out, text, max_bytes)
}

fn extract_plain_text_limited(
    html: &[u8],
    max_bytes: usize,
    out: &mut String,
) -> Result<(), EpubError> {
    let mut reader = Reader::from_reader(html);
    reader.config_mut().trim_text(false);
    reader.config_mut().expand_empty_elements = false;

    let mut buf = Vec::new();
    let mut skip_depth = 0usize;
    let mut done = false;

    while !done {
        match reader.read_event_into(&mut buf) {
            Ok(Event::Start(e)) => {
                let name = reader
                    .decoder()
                    .decode(e.name().as_ref())
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?
                    .to_string();
                if should_skip_text_tag(&name) {
                    skip_depth += 1;
                } else if skip_depth == 0
                    && matches!(name.as_str(), "p" | "div" | "li")
                    && push_newline_limited(out, max_bytes)
                {
                    done = true;
                }
            }
            Ok(Event::Empty(e)) => {
                if skip_depth > 0 {
                    buf.clear();
                    continue;
                }
                let name = reader
                    .decoder()
                    .decode(e.name().as_ref())
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?
                    .to_string();
                if matches!(name.as_str(), "br" | "p" | "div" | "li")
                    && push_newline_limited(out, max_bytes)
                {
                    done = true;
                }
            }
            Ok(Event::End(e)) => {
                let name = reader
                    .decoder()
                    .decode(e.name().as_ref())
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?
                    .to_string();
                if should_skip_text_tag(&name) {
                    skip_depth = skip_depth.saturating_sub(1);
                } else if skip_depth == 0
                    && matches!(name.as_str(), "p" | "div" | "li")
                    && push_newline_limited(out, max_bytes)
                {
                    done = true;
                }
            }
            Ok(Event::Text(e)) => {
                if skip_depth > 0 {
                    buf.clear();
                    continue;
                }
                let text = e
                    .decode()
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?
                    .to_string();
                let normalized = normalize_plain_text_whitespace(&text);
                if push_text_limited(out, &normalized, max_bytes) {
                    done = true;
                }
            }
            Ok(Event::CData(e)) => {
                if skip_depth > 0 {
                    buf.clear();
                    continue;
                }
                let text = reader
                    .decoder()
                    .decode(&e)
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?
                    .to_string();
                let normalized = normalize_plain_text_whitespace(&text);
                if push_text_limited(out, &normalized, max_bytes) {
                    done = true;
                }
            }
            Ok(Event::GeneralRef(e)) => {
                if skip_depth > 0 {
                    buf.clear();
                    continue;
                }
                let entity_name = e
                    .decode()
                    .map_err(|err| EpubError::Parse(format!("Decode error: {:?}", err)))?;
                let entity = format!("&{};", entity_name);
                let resolved = quick_xml::escape::unescape(&entity)
                    .map_err(|err| EpubError::Parse(format!("Unescape error: {:?}", err)))?
                    .to_string();
                let normalized = normalize_plain_text_whitespace(&resolved);
                if push_text_limited(out, &normalized, max_bytes) {
                    done = true;
                }
            }
            Ok(Event::Eof) => break,
            Ok(_) => {}
            Err(err) => return Err(EpubError::Parse(format!("XML error: {:?}", err))),
        }
        buf.clear();
    }

    if out.ends_with('\n') {
        out.pop();
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::render_prep::{RenderPrep, RenderPrepOptions, RenderPrepTrace, StyledEventOrRun};

    #[test]
    fn test_resolve_opf_relative_path() {
        assert_eq!(
            resolve_opf_relative_path("EPUB/package.opf", "text/ch1.xhtml"),
            "EPUB/text/ch1.xhtml"
        );
        assert_eq!(
            resolve_opf_relative_path("OEBPS/content.opf", "../toc.ncx"),
            "toc.ncx"
        );
        assert_eq!(
            resolve_opf_relative_path("package.opf", "chapter.xhtml#p1"),
            "chapter.xhtml"
        );
        assert_eq!(
            resolve_opf_relative_path("EPUB/package.opf", "/META-INF/container.xml"),
            "META-INF/container.xml"
        );
    }

    #[test]
    fn test_read_resource_into_streams_to_writer() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");

        let mut out = Vec::new();
        let n = book
            .read_resource_into("xhtml/nav.xhtml", &mut out)
            .expect("resource should stream");
        assert_eq!(n, out.len());
        assert!(!out.is_empty());
    }

    #[test]
    fn test_chapter_text_into_matches_chapter_text() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let baseline = book.chapter_text(0).expect("chapter text should extract");
        let mut out = String::new();
        book.chapter_text_into(0, &mut out)
            .expect("chapter text into should extract");
        assert_eq!(baseline, out);
    }

    #[test]
    fn test_chapter_text_with_limit_truncates_safely() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let full = book.chapter_text(0).expect("full text should extract");
        let limited = book
            .chapter_text_with_limit(0, 64)
            .expect("limited text should extract");
        assert!(limited.len() <= 64);
        assert!(full.starts_with(&limited));
    }

    #[test]
    fn test_chapter_text_with_zero_limit_is_empty() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let limited = book
            .chapter_text_with_limit(0, 0)
            .expect("limited text should extract");
        assert!(limited.is_empty());
    }

    #[test]
    fn test_chapter_text_into_with_limit_clears_existing_buffer() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let mut out = String::from("stale content");
        book.chapter_text_into_with_limit(0, 32, &mut out)
            .expect("limited text should extract");
        assert!(!out.starts_with("stale content"));
        assert!(out.len() <= 32);
    }

    #[test]
    fn test_extract_plain_text_limited_preserves_utf8_boundaries() {
        let html = "<p>hello ðŸ˜€ world</p>";
        let mut out = String::new();
        extract_plain_text_limited(html.as_bytes(), 8, &mut out).expect("extract should succeed");
        assert!(out.len() <= 8);
        assert!(core::str::from_utf8(out.as_bytes()).is_ok());
    }

    #[test]
    fn test_chapter_stylesheets_api_works() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let styles = book
            .chapter_stylesheets(0)
            .expect("chapter_stylesheets should succeed");
        assert!(styles.sources.iter().all(|s| !s.href.is_empty()));
    }

    #[test]
    fn test_embedded_fonts_api_works() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let fonts = book
            .embedded_fonts()
            .expect("embedded_fonts should succeed");
        assert!(fonts.len() <= crate::render_prep::FontLimits::default().max_faces);
    }

    #[test]
    fn test_render_prep_golden_path_prepare_chapter() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let mut prep = RenderPrep::new(RenderPrepOptions::default())
            .with_serif_default()
            .with_embedded_fonts_from_book(&mut book)
            .expect("font registration should succeed");
        let index = (0..book.chapter_count())
            .find(|idx| {
                book.chapter_text_with_limit(*idx, 256)
                    .map(|s| !s.trim().is_empty())
                    .unwrap_or(false)
            })
            .unwrap_or(0);
        let chapter = prep
            .prepare_chapter(&mut book, index)
            .expect("prepare_chapter should succeed");
        assert!(chapter.iter().count() > 0);
    }

    #[test]
    fn test_chapter_styled_runs_api_returns_items() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let index = (0..book.chapter_count())
            .find(|idx| {
                book.chapter_text_with_limit(*idx, 256)
                    .map(|s| !s.trim().is_empty())
                    .unwrap_or(false)
            })
            .unwrap_or(0);
        let styled = book
            .chapter_styled_runs(index)
            .expect("chapter_styled_runs should succeed");
        assert!(styled.iter().count() > 0);
    }

    #[test]
    fn test_render_prep_prepare_chapter_into_streams_items() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let index = (0..book.chapter_count())
            .find(|idx| {
                book.chapter_text_with_limit(*idx, 256)
                    .map(|s| !s.trim().is_empty())
                    .unwrap_or(false)
            })
            .unwrap_or(0);
        let mut prep = RenderPrep::new(RenderPrepOptions::default())
            .with_serif_default()
            .with_embedded_fonts_from_book(&mut book)
            .expect("font registration should succeed");
        let mut out = Vec::new();
        prep.prepare_chapter_into(&mut book, index, &mut out)
            .expect("prepare_chapter_into should succeed");
        assert!(!out.is_empty());
    }

    #[test]
    fn test_render_prep_runs_persist_resolved_font_id() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let index = (0..book.chapter_count())
            .find(|idx| {
                book.chapter_text_with_limit(*idx, 256)
                    .map(|s| !s.trim().is_empty())
                    .unwrap_or(false)
            })
            .unwrap_or(0);
        let mut prep = RenderPrep::new(RenderPrepOptions::default())
            .with_serif_default()
            .with_embedded_fonts_from_book(&mut book)
            .expect("font registration should succeed");

        let mut saw_run = false;
        prep.prepare_chapter_with_trace_context(&mut book, index, |item, trace| {
            if let StyledEventOrRun::Run(run) = item {
                saw_run = true;
                let font_trace = trace.font_trace().expect("run should include font trace");
                assert_eq!(run.font_id, font_trace.face.font_id);
                assert_eq!(run.resolved_family, font_trace.face.family);
            }
        })
        .expect("prepare_chapter_with_trace_context should succeed");
        assert!(saw_run);
    }

    #[test]
    fn test_render_prep_trace_context_contains_font_and_style_for_runs() {
        let file = std::fs::File::open(
            "tests/fixtures/Fundamental-Accessibility-Tests-Basic-Functionality-v2.0.0.epub",
        )
        .expect("fixture should open");
        let mut book = EpubBook::from_reader(file).expect("book should open");
        let index = (0..book.chapter_count())
            .find(|idx| {
                book.chapter_text_with_limit(*idx, 256)
                    .map(|s| !s.trim().is_empty())
                    .unwrap_or(false)
            })
            .unwrap_or(0);
        let mut prep = RenderPrep::new(RenderPrepOptions::default())
            .with_serif_default()
            .with_embedded_fonts_from_book(&mut book)
            .expect("font registration should succeed");

        let mut saw_run = false;
        prep.prepare_chapter_with_trace_context(&mut book, index, |item, trace| match item {
            StyledEventOrRun::Run(run) => {
                saw_run = true;
                match trace {
                    RenderPrepTrace::Run { style, font } => {
                        assert_eq!(style.as_ref(), &run.style);
                        assert_eq!(font.face.font_id, run.font_id);
                        assert_eq!(font.face.family, run.resolved_family);
                    }
                    RenderPrepTrace::Event => panic!("run item should produce run trace context"),
                }
            }
            StyledEventOrRun::Event(_) => {
                assert!(matches!(trace, RenderPrepTrace::Event));
            }
        })
        .expect("prepare_chapter_with_trace_context should succeed");
        assert!(saw_run);
    }

    #[test]
    fn test_reading_session_resolve_locator_and_progress() {
        let chapters = vec![
            ChapterRef {
                index: 0,
                idref: "c1".to_string(),
                href: "text/ch1.xhtml".to_string(),
                media_type: "application/xhtml+xml".to_string(),
            },
            ChapterRef {
                index: 1,
                idref: "c2".to_string(),
                href: "text/ch2.xhtml".to_string(),
                media_type: "application/xhtml+xml".to_string(),
            },
        ];
        let nav = Navigation {
            toc: vec![NavPoint {
                label: "intro".to_string(),
                href: "text/ch2.xhtml#start".to_string(),
                children: Vec::new(),
            }],
            page_list: Vec::new(),
            landmarks: Vec::new(),
        };
        let mut session = ReadingSession::new(chapters, Some(nav));
        let resolved = session
            .resolve_locator(Locator::TocId("intro".to_string()))
            .expect("toc id should resolve");
        assert_eq!(resolved.chapter.index, 1);
        assert_eq!(resolved.fragment.as_deref(), Some("start"));
        assert!(session.book_progress() > 0.0);
    }

    #[test]
    fn test_reading_session_seek_position_out_of_bounds() {
        let chapters = vec![ChapterRef {
            index: 0,
            idref: "c1".to_string(),
            href: "text/ch1.xhtml".to_string(),
            media_type: "application/xhtml+xml".to_string(),
        }];
        let mut session = ReadingSession::new(chapters, None);
        let err = session
            .seek_position(&ReadingPosition {
                chapter_index: 2,
                chapter_href: None,
                anchor: None,
                fallback_offset: 0,
            })
            .expect_err("seek should fail");
        assert!(matches!(err, EpubError::ChapterOutOfBounds { .. }));
    }
}
